{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_kernel(model):\n",
    "    model_weights = model.state_dict()\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for idx, filt  in enumerate(model_weights['conv1.weight']):\n",
    "    #print(filt[0, :, :])\n",
    "        if idx >= 32: continue\n",
    "        plt.subplot(4,8, idx + 1)\n",
    "        plt.imshow(filt[0, :, :], cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_kernel_output(model,images):\n",
    "    fig1 = plt.figure()\n",
    "    plt.figure(figsize=(1,1))\n",
    "    \n",
    "    img_normalized = (images[0] - images[0].min()) / (images[0].max() - images[0].min())\n",
    "    plt.imshow(img_normalized.numpy().transpose(1,2,0))\n",
    "    plt.show()\n",
    "    output = model.conv1(images)\n",
    "    layer_1 = output[0, :, :, :]\n",
    "    layer_1 = layer_1.data\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for idx, filt  in enumerate(layer_1):\n",
    "        if idx >= 32: continue\n",
    "        plt.subplot(4,8, idx + 1)\n",
    "        plt.imshow(filt, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def test_accuracy(net, dataloader):\n",
    "  ########TESTING PHASE###########\n",
    "  \n",
    "    #check accuracy on whole test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval() #important for deactivating dropout and correctly use batchnorm accumulated statistics\n",
    "    with torch.no_grad():\n",{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: torch-1.1.0-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\n",
      "WARNING: You are using pip version 19.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\alberto\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\alberto\\anaconda3\\lib\\site-packages (from torchvision) (5.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\alberto\\anaconda3\\lib\\site-packages (from torchvision) (1.16.0)\n",
      "Requirement already satisfied: torch in c:\\users\\alberto\\anaconda3\\lib\\site-packages (from torchvision) (1.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\alberto\\anaconda3\\lib\\site-packages (from torchvision) (1.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q http://download.pytorch.org/whl/cu90/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES FOR PROJECT\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM FUNCTIONS\n",
    "import random\n",
    "\n",
    "def FUNZIONE1(originalDict):\n",
    "    # class0 = class dropped\n",
    "    # class1 = class \"others\"\n",
    "    \n",
    "    classToDrop = list(originalDict)[len(originalDict.keys())-1]\n",
    "    \n",
    "    class0, class1 = FUNZIONE2(originalDict, classToDrop)\n",
    "\n",
    "    print('Class ' + classToDrop + ' dropped')\n",
    "    #print('class0 = ', end = '')\n",
    "    #print(class0)\n",
    "    #print('class1 = ', end = '')\n",
    "    #print(class1)\n",
    "    print()\n",
    "\n",
    "    if len(class1.keys()) == 1:\n",
    "        dictForCNN = {list(class1.keys())[0]: class1[list(class1.keys())[0]], classToDrop: class0}\n",
    "        #print(dictForCNN)\n",
    "        return class1\n",
    "    # elements from each class\n",
    "    elementsFromEachClass = int(round(len(class0) / len(class1.keys())))\n",
    "    print('We will take ' + str(elementsFromEachClass) + ' elements from each class ')\n",
    "    class1_balanced = []\n",
    "    for k in class1.keys():\n",
    "        myClassElements = class1[k]\n",
    "    #print('class ' + k + ' has elements = ', end = '')\n",
    "    #print(myClassElements)\n",
    "        random.shuffle(myClassElements)\n",
    "    #print('Taking these elements after shuffle: ', end = '')\n",
    "    #print(myClassElements[:elementsFromEachClass])\n",
    "        print()\n",
    "        class1_balanced += myClassElements[:elementsFromEachClass]\n",
    "    \n",
    "    dictForCNN = {}\n",
    "    \n",
    "    dictForCNN.update({'others': []})\n",
    "    dictForCNN.update({classToDrop: []})\n",
    "        \n",
    "    for i in class1_balanced:\n",
    "        dictForCNN['others'].append(i)\n",
    "    for i in class0:\n",
    "        dictForCNN[classToDrop].append(i)\t\n",
    "    #dictForCNN = {'others': class1_balanced, classToDrop: class0}\n",
    "    #print('Final dict is: ', end = '')\n",
    "    #print(dictForCNN)\n",
    "    return class1, dictForCNN.values(), dictForCNN.keys()\n",
    "\n",
    "def FUNZIONE2(mydict, className):\n",
    "    return mydict.pop(className), mydict\n",
    "\n",
    "def toDICT(trainset):\n",
    "    mydict = {}\n",
    "    for data, label in zip(trainset.data, trainset.targets):\n",
    "        label = str(label)\n",
    "        if label in mydict.keys():\n",
    "            mydict[label].append(data)\n",
    "        else:\n",
    "            mydict.update({label: []})\n",
    "            mydict[label].append(data)\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR10' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-cf073764b8f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mtoDICT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[0mFUNZIONE1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-bf18061ded62>\u001b[0m in \u001b[0;36mtoDICT\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtoDICT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mmydict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmydict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CIFAR10' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_kernel(model):\n",
    "    model_weights = model.state_dict()\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for idx, filt  in enumerate(model_weights['conv1.weight']):\n",
    "    #print(filt[0, :, :])\n",
    "        if idx >= 32: continue\n",
    "        plt.subplot(4,8, idx + 1)\n",
    "        plt.imshow(filt[0, :, :], cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_kernel_output(model,images):\n",
    "    fig1 = plt.figure()\n",
    "    plt.figure(figsize=(1,1))\n",
    "    \n",
    "    img_normalized = (images[0] - images[0].min()) / (images[0].max() - images[0].min())\n",
    "    plt.imshow(img_normalized.numpy().transpose(1,2,0))\n",
    "    plt.show()\n",
    "    output = model.conv1(images)\n",
    "    layer_1 = output[0, :, :, :]\n",
    "    layer_1 = layer_1.data\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for idx, filt  in enumerate(layer_1):\n",
    "        if idx >= 32: continue\n",
    "        plt.subplot(4,8, idx + 1)\n",
    "        plt.imshow(filt, cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def test_accuracy(net, dataloader):\n",
    "  ########TESTING PHASE###########\n",
    "  \n",
    "    #check accuracy on whole test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval() #important for deactivating dropout and correctly use batchnorm accumulated statistics\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy of the network on the test set: %d %%' % (\n",
    "    accuracy))\n",
    "    return accuracy\n",
    "\n",
    "    \n",
    "n_classes = 2       \n",
    "      \n",
    "#function to define the convolutional network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #conv2d first parameter is the number of kernels at input (you get it from the output value of the previous layer)\n",
    "        #conv2d second parameter is the number of kernels you wanna have in your convolution, so it will be the n. of kernels at output.\n",
    "        #conv2d third, fourth and fifth parameters are, as you can read, kernel_size, stride and zero padding :)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv_final = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 4096)\n",
    "        self.fc2 = nn.Linear(4096, n_classes) #last FC for classification \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.pool(self.conv_final(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #hint: dropout goes here!\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "      ####RUNNING CODE FROM HERE:\n",
    "      \n",
    "#transform are heavily used to do simple and complex transformation and data augmentation\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "     #transforms.RandomHorizontalFlip(),\n",
    "     transforms.Resize((32,32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "     transforms.Resize((32,32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     ])\n",
    "\n",
    "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True\"\"\", transform=transform_train\"\"\")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform_train)\n",
    "\n",
    "mydict = toDICT(trainset)\n",
    "trainset_old, trainset.data, trainset.targets = FUNZIONE1(mydict)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=4,drop_last=True)\n",
    "\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True\"\"\", transform=transform_test\"\"\")\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
    "                                         shuffle=False, num_workers=4,drop_last=True)\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "#show images just to understand what is inside the dataset\n",
    "#images, labels = dataiter.next()\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "net = CNN()\n",
    "\n",
    "###OPTIONAL:\n",
    "#print(\"####plotting kernels of conv1 layer:####\")\n",
    "#plot_kernel(net)\n",
    "####\n",
    "\n",
    "\n",
    "net = net.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda() #it already does softmax computation for use!\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001) #better convergency w.r.t simple SGD :)\n",
    "\n",
    "###OPTIONAL:\n",
    "#print(\"####plotting output of conv1 layer:#####\")\n",
    "#plot_kernel_output(net,images)  \n",
    "###\n",
    "\n",
    "########TRAINING PHASE###########\n",
    "n_loss_print = len(trainloader)  #print every epoch, use smaller numbers if you wanna print loss more often!\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    net.train() #important for activating dropout and correctly train batchnorm\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs and cast them into cuda wrapper\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_loss_print == (n_loss_print -1):    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / n_loss_print))\n",
    "            running_loss = 0.0\n",
    "    test_accuracy(net,testloader)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATASET CLEANING\n",
    "\n",
    "Since the patient_id is not useful for classification purpose,\n",
    "we move the dataset into a folder containing X sub-folders\n",
    "where X is defined as the number of possible classes.\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "def refactor_dataset():    \n",
    "    for count, folder_name in enumerate(os.listdir(\"./DatasetINPUT/\")):\n",
    "        for file_name in os.listdir(\"./DatasetINPUT/\" + folder_name):\n",
    "            os.rename(file_name, \"./DatasetOUTPUT/\" + file_name.split(\"_\")[1] + \"/\" + file_name)\n",
    "    os.remove(\"DatasetINPUT\")\n",
    "    os.rename(\"DatasestOUTPUT\", \"Dataset\")\n",
    "            \n",
    "def make_folders_tree(folder_names):\n",
    "    for folder_name in folder_names:\n",
    "        mkdir_if_not_exist(folder_name)\n",
    "               \n",
    "@staticmethod\n",
    "def mkdir_if_not_exist(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        \n",
    "make_folders_tree([\"AC\", \"H\", \"Serr\", \"T\", \"V\"])\n",
    "refactor_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy of the network on the test set: %d %%' % (\n",
    "    accuracy))\n",
    "    return accuracy\n",
    "\n",
    "    \n",
    "n_classes = 10       \n",
    "      \n",
    "#function to define the convolutional network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #conv2d first parameter is the number of kernels at input (you get it from the output value of the previous layer)\n",
    "        #conv2d second parameter is the number of kernels you wanna have in your convolution, so it will be the n. of kernels at output.\n",
    "        #conv2d third, fourth and fifth parameters are, as you can read, kernel_size, stride and zero padding :)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv_final = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 4096)\n",
    "        self.fc2 = nn.Linear(4096, n_classes) #last FC for classification \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.pool(self.conv_final(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #hint: dropout goes here!\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "      ####RUNNING CODE FROM HERE:\n",
    "      \n",
    "#transform are heavily used to do simple and complex transformation and data augmentation\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "     #transforms.RandomHorizontalFlip(),\n",
    "     transforms.Resize((32,32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "     transforms.Resize((32,32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=4,drop_last=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
    "                                         shuffle=False, num_workers=4,drop_last=True)\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "#show images just to understand what is inside the dataset\n",
    "#images, labels = dataiter.next()\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "net = CNN()\n",
    "\n",
    "###OPTIONAL:\n",
    "#print(\"####plotting kernels of conv1 layer:####\")\n",
    "#plot_kernel(net)\n",
    "####\n",
    "\n",
    "\n",
    "net = net.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda() #it already does softmax computation for use!\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001) #better convergency w.r.t simple SGD :)\n",
    "\n",
    "###OPTIONAL:\n",
    "#print(\"####plotting output of conv1 layer:#####\")\n",
    "#plot_kernel_output(net,images)  \n",
    "###\n",
    "\n",
    "########TRAINING PHASE###########\n",
    "n_loss_print = len(trainloader)  #print every epoch, use smaller numbers if you wanna print loss more often!\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    net.train() #important for activating dropout and correctly train batchnorm\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs and cast them into cuda wrapper\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_loss_print == (n_loss_print -1):    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / n_loss_print))\n",
    "            running_loss = 0.0\n",
    "    test_accuracy(net,testloader)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATASET CLEANING\n",
    "\n",
    "Since the patient_id is not useful for classification purpose,\n",
    "we move the dataset into a folder containing X sub-folders\n",
    "where X is defined as the number of possible classes.\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "def refactor_dataset():    \n",
    "    for count, folder_name in enumerate(os.listdir(\"./DatasetINPUT/\")):\n",
    "        for file_name in os.listdir(\"./DatasetINPUT/\" + folder_name):\n",
    "            os.rename(file_name, \"./DatasetOUTPUT/\" + file_name.split(\"_\")[1] + \"/\" + file_name)\n",
    "    os.remove(\"DatasetINPUT\")\n",
    "    os.rename(\"DatasestOUTPUT\", \"Dataset\")\n",
    "            \n",
    "def make_folders_tree(folder_names):\n",
    "    for folder_name in folder_names:\n",
    "        mkdir_if_not_exist(folder_name)\n",
    "               \n",
    "@staticmethod\n",
    "def mkdir_if_not_exist(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        \n",
    "make_folders_tree([\"AC\", \"H\", \"Serr\", \"T\", \"V\"])\n",
    "refactor_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
